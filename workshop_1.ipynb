{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python + Pandas 新手工作坊：鐵達尼號生存分析\n",
    "\n",
    "歡迎來到我們的 Python + Pandas 新手工作坊！在這個工作坊中，我們將帶你從零開始，使用 **Python** 中最受歡迎的資料分析工具 **Pandas**，透過經典的**鐵達尼號生存資料集**來學習資料處理的基礎。\n",
    "\n",
    "## 學習效益\n",
    "\n",
    "你會學到資料科學中最核心的技能，包括：\n",
    "\n",
    "* **認識 Pandas 的核心資料結構：** Series 和 DataFrame。\n",
    "* **資料載入與初步探索：** 快速了解資料的概貌。\n",
    "* **資料清理與預處理：** 處理缺失值、新增/修改/刪除欄位。\n",
    "* **資料篩選與排序：** 根據條件提取和整理資料。\n",
    "* **資料分組與聚合：** 從資料中提取有用的統計資訊。\n",
    "* **簡單資料視覺化：** 將資料轉化為易於理解的圖表。\n",
    "\n",
    "這些技能是進行更進階的資料分析、機器學習甚至是**深度學習**的基石。在工作坊的最後，我們甚至會展示你的資料清理成果如何影響一個簡單的深度學習模型！\n",
    "\n",
    "準備好了嗎？讓我們開始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 1.1 環境準備：Jupyter Notebook/Lab 使用指南\n",
    "\n",
    "**Jupyter Notebook** (或 **Jupyter Lab**) 是一個基於瀏覽器的互動式開發環境，它允許你將程式碼、程式碼輸出、解釋性文字和圖表整合在一個文件中。這對資料科學和教學來說非常方便。\n",
    "\n",
    "### 基本操作\n",
    "\n",
    "* **單元格 (Cell)：** Jupyter Notebook 由一個個「單元格」組成。每個單元格可以是程式碼 (Code) 或 Markdown (文字說明)。\n",
    "* **運行 Cell：** 點選 Cell，然後按下 `Shift + Enter` 鍵，或者點擊上方工具列的 `▶ Run` 按鈕，即可執行 Cell 中的內容。\n",
    "* **新增 Cell：** 點選上方工具列的 `+` 按鈕，或在 Cell 選中時（非編輯模式下）按下 `A` (在上方插入) 或 `B` (在下方插入)。\n",
    "* **切換 Cell 類型：** 在選中 Cell 時，點擊上方工具列的下拉選單，可以將其從 `Code` 切換為 `Markdown` (或反之)。\n",
    "* **保存：** 點擊上方工具列的磁碟圖標，或者按下 `Ctrl + S` (Windows/Linux) 或 `Cmd + S` (macOS)。\n",
    "\n",
    "### 開始你的第一個程式碼！\n",
    "\n",
    "在下方的 Cell 中，我們將載入 Pandas 函式庫。請運行它，並觀察輸出。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入 Pandas 函式庫，並使用 pd 作為簡稱 (這是約定俗成的用法)\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Pandas 函式庫載入成功！版本號：\", pd.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2.1 Pandas 是什麼？為何學習它？\n",
    "\n",
    "**Pandas** 是 Python 中一個**廣受歡迎且功能強大**的開源函式庫，專門用於資料操作與分析。它提供高效的工具，能夠用簡潔的幾行程式碼進行複雜的資料處理。\n",
    "\n",
    "### 為何在資料科學和深度學習中如此重要？\n",
    "\n",
    "想像一下，你的數據就像散落在各處的樂高積木：有些髒了、有些丟失了、有些形狀不對。\n",
    "\n",
    "* **資料清洗：** Pandas 就像你的清理工具組，能幫你擦拭髒污 (處理缺失值)、找到丟失的積木 (填補資料) 或移除多餘的積木 (刪除重複值)。\n",
    "* **資料整理：** 它可以將散亂的積木整理成整齊的表格 (DataFrame)，方便你組合和堆疊。\n",
    "* **特徵工程：** 你甚至可以用現有的積木組合出新的、更有用的積木 (創建新欄位)。\n",
    "\n",
    "對於未來的**機器學習與深度學習**，模型需要的是**乾淨、整理好、格式正確**的數據。Pandas 就是你準備這些數據的**第一把交椅**！沒有它，你很難有效地將原始數據轉換為模型可以理解和學習的格式。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 2.2 Pandas 的兩大核心資料結構：Series 和 DataFrame\n",
    "\n",
    "Pandas 主要提供兩種核心資料結構，它們是你進行資料操作的基礎：\n",
    "\n",
    "### 1. Series (系列)\n",
    "\n",
    "* **一維資料結構：** 想像它像 Excel 表格中的「**單一欄位**」，或者像一個帶有標籤 (索引) 的 Python 列表。\n",
    "* **組成：** 每個值都有一個唯一的標籤 (索引 `index`) 和對應的實際資料值 (值 `values`)。\n",
    "* **應用：** 適合儲存一組相關聯的數據，例如「所有乘客的年齡」或「某個班級的所有分數」。\n",
    "\n",
    "### 2. DataFrame (資料框)\n",
    "\n",
    "* **二維資料結構：** 這是 Pandas 中最常用的對象，想像它就像一個「**完整的 Excel 工作表**」或資料庫中的一張「表格」。\n",
    "* **組成：** 它由多個「行 (rows)」和多個「列 (columns)」組成。每「列」實際上就是一個 Series。\n",
    "* **應用：** 非常適合處理像 CSV 檔案、網頁表格或資料庫中的**表格式資料**。鐵達尼號的資料就是典型的 DataFrame 格式。\n",
    "\n",
    "下圖簡單展示了 Series 和 DataFrame 的結構差異：\n",
    "\n",
    "![Series vs DataFrame](https://pandas.pydata.org/docs/getting_started/overview/_images/01_table_dataframe.svg)\n",
    "圖片來源: Pandas 官方文件\n",
    "\n",
    "讓我們透過範例來建立它們並觀察它們的樣子。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：建立一個 Series\n",
    "# 這裡我們建立一個表示學生分數的 Series\n",
    "# index 是每個資料點的標籤\n",
    "student_scores = pd.Series([85, 92, 78, 65], index=['Alice', 'Bob', 'Charlie', 'David'])\n",
    "\n",
    "print(\"這是一個 Series (學生分數)：\")\n",
    "print(student_scores)\n",
    "\n",
    "print(\"\\nSeries 的資料類型是：\", type(student_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：建立一個 DataFrame\n",
    "# 這裡我們用一個 Python 字典來建立 DataFrame\n",
    "# 字典的 key 會成為 DataFrame 的欄位名稱\n",
    "employee_data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'London', 'Paris'],\n",
    "    'Salary': [60000, 75000, 80000]\n",
    "}\n",
    "df_employees = pd.DataFrame(employee_data)\n",
    "\n",
    "print(\"這是一個 DataFrame (員工資料)：\")\n",
    "print(df_employees)\n",
    "\n",
    "print(\"\\nDataFrame 的資料類型是：\", type(df_employees))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 3.1 載入鐵達尼號生存資料\n",
    "\n",
    "現在，我們將載入本次工作坊的主角——**鐵達尼號生存資料集**。\n",
    "\n",
    "**`pd.read_csv()`** 是 Pandas 中用於載入 CSV (逗號分隔值) 檔案的最常用方法。CSV 檔案是儲存表格資料的常見格式。\n",
    "\n",
    "### **重要提醒：**\n",
    "\n",
    "請確保你的 `titanic_survival.csv` 檔案與你目前這個 Jupyter Notebook (.ipynb 檔案) 放在**同一個資料夾**中。如果不在同一個資料夾，你需要提供完整的檔案路徑 (例如：`'C:/Users/YourUser/Desktop/titanic_survival.csv'`)。這是新手最常遇到問題的地方！\n",
    "\n",
    "讓我們來載入它吧！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入鐵達尼號資料集\n",
    "# 我們將載入的資料儲存在一個名為 df 的變數中，df 是 DataFrame 的常用簡寫\n",
    "df = pd.read_csv('titanic_survival.csv')\n",
    "\n",
    "print(\"鐵達尼號資料集載入成功！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 4.1 初步探索資料概貌\n",
    "\n",
    "在開始任何深入分析之前，第一步總是「**了解你的資料長什麼樣子**」。Pandas 提供了一系列快速查看資料概況的方法。\n",
    "\n",
    "* **`df.head(n=5)`：** 顯示 DataFrame 的**前 n 行** (預設是 5 行)，可以快速概覽資料的結構和內容。\n",
    "* **`df.tail(n=5)`：** 顯示 DataFrame 的**後 n 行** (預設是 5 行)，有助於檢查資料的結尾部分。\n",
    "* **`df.columns`：** 查看 DataFrame 中所有**欄位 (列) 的名稱**。\n",
    "* **`df.info()`：** 顯示資料的**完整摘要資訊**，包括每個欄位的非空值數量、資料類型 (`Dtype`)，這對於初步識別**缺失值**非常有用。\n",
    "* **`df.shape`：** 顯示資料的**形狀**，即 `(行數, 列數)`，讓你快速知道資料集的大小。\n",
    "* **`df.describe()`：** 顯示數值型欄位的**描述性統計**，包括計數、平均值、標準差、最小值、最大值和四分位數。\n",
    "\n",
    "讓我們來使用這些方法探索鐵達尼號資料吧！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [新增] 欄位說明\n",
    "在我們開始探索之前，先了解一下每個欄位的意義：\n",
    "\n",
    "* **PassengerId**: 乘客編號\n",
    "* **Survived**: 是否存活 (0 = 否, 1 = 是)\n",
    "* **Pclass**: 乘客艙等 (1 = 頭等艙, 2 = 商務艙, 3 = 經濟艙)\n",
    "* **Name**: 姓名\n",
    "* **Sex**: 性別\n",
    "* **Age**: 年齡\n",
    "* **SibSp**: 船上的兄弟姐妹/配偶數量\n",
    "* **Parch**: 船上的父母/子女數量\n",
    "* **Ticket**: 船票號碼\n",
    "* **Fare**: 票價\n",
    "* **Cabin**: 船艙號碼\n",
    "* **Embarked**: 登船港口 (C = Cherbourg, Q = Queenstown, S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看資料集前 5 行：df.head()\n",
    "print(\"1. 資料集前 5 行：\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看資料集後 5 行：df.tail()\n",
    "print(\"2. 資料集後 5 行：\")\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看所有欄位名稱：df.columns\n",
    "print(\"3. 所有欄位名稱：\")\n",
    "print(df.columns.tolist()) # .tolist() 可以讓它顯示得更漂亮"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看資料的整體資訊 (資料類型、非空值數量)：df.info()\n",
    "# 這是非常重要的一步！可以幫我們快速發現 Age, Cabin, Embarked 有缺失值 (Missing Values)\n",
    "print(\"4. 資料集整體資訊：\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看資料的形狀 (行數, 列數)：df.shape\n",
    "print(\"5. 資料集形狀 (行數, 列數)：\")\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [新增] 查看數值型欄位的描述性統計：df.describe()\n",
    "# 這可以幫助我們了解資料的分佈情況，例如年齡的平均值、票價的極端值等\n",
    "print(\"6. 數值型欄位描述性統計：\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 5.1 存取特定欄位\n",
    "\n",
    "在 Pandas DataFrame 中，你可以像操作 Python 字典或列表一樣來選擇特定的欄位（列）。\n",
    "\n",
    "* **選擇單一欄位：** 使用單個中括號 `[]` 並在其中放入欄位名稱（字串）。結果會是一個 **Series**。\n",
    "  ```python\n",
    "  df['ColumnName']\n",
    "  ```\n",
    "* **選擇多個欄位：** 使用雙層中括號 `[[]]`，內層是一個包含所有你想選取欄位名稱的**列表**。結果會是一個 **DataFrame**。\n",
    "  ```python\n",
    "  df[['Column1', 'Column2']]\n",
    "  ```\n",
    "\n",
    "這是一個非常基礎但重要的操作。讓我們實際操作看看！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇單一欄位 (回傳 Series)：乘客姓名 'Name'\n",
    "passenger_names = df['Name']\n",
    "\n",
    "print(\"乘客姓名欄位 (Series)：\")\n",
    "print(passenger_names.head()) # .head() 幫助我們只看前幾行，避免輸出過長\n",
    "\n",
    "print(\"\\n選擇單一欄位後，資料類型是：\", type(passenger_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 選擇多個欄位 (回傳 DataFrame)：'Name' 和 'Age'\n",
    "name_and_age = df[['Name', 'Age']]\n",
    "\n",
    "print(\"選擇 'Name' 和 'Age' 欄位 (DataFrame)：\")\n",
    "print(name_and_age.head()) # 注意這裡的雙層中括號！\n",
    "\n",
    "print(\"\\n選擇多個欄位後，資料類型是：\", type(name_and_age))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 5.2 練習題：存取資料\n",
    "\n",
    "現在輪到你練習了！\n",
    "\n",
    "請運行以下程式碼，它會導致錯誤。**請觀察錯誤訊息，並嘗試找出問題所在。** 你的目標是**正確選取出 'Age' 和 'Fare' 這兩個欄位**。\n",
    "\n",
    "### 任務\n",
    "\n",
    "1.  運行下方的 Code Cell。\n",
    "2.  仔細閱讀錯誤訊息，它會告訴你哪裡不對勁。\n",
    "3.  根據錯誤訊息和你所學的知識，修正程式碼，使其能成功選取 'Age' 和 'Fare' 欄位。\n",
    "4.  (可選) 嘗試將錯誤訊息複製貼上到 Google 或 ChatGPT 中，看看它們會給你什麼建議！這是解決問題的重要技能。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 錯誤示範：請觀察錯誤訊息並修正！\n",
    "# 目標：選取 'Age' 和 'Fare' 欄位\n",
    "selected_columns = df['Age', 'Fare'].head()\n",
    "print(selected_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: 20px; color: blue; cursor: pointer;\">點我查看提示與解答 (請先嘗試自行修正後再展開)</summary>\n",
    "\n",
    "### 提示\n",
    "\n",
    "* 當你需要選取**多個**欄位時，你需要傳遞一個「**列表**」給中括號 `[]`。列表的語法是 `[元素1, 元素2, ...]`。\n",
    "* 錯誤訊息 `KeyError: ('Age', 'Fare')` 表明 Pandas 把 `('Age', 'Fare')` 當成一個**單一的鍵** (一個元組 Tuple)，而不是兩個獨立的欄位名稱。Pandas 找不到一個叫做 `('Age', 'Fare')` 的欄位，所以報錯。\n",
    "\n",
    "### 正確程式碼\n",
    "\n",
    "```python\n",
    "# 正確的寫法是將欄位名稱放在一個列表中\n",
    "selected_columns_correct = df[['Age', 'Fare']].head()\n",
    "print(selected_columns_correct)\n",
    "print(\"\\n選取多個欄位後的資料類型是：\", type(selected_columns_correct))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 6.1 處理缺失值 (Missing Values)\n",
    "\n",
    "在真實世界的資料中，很少有資料是完全乾淨的。**缺失值** (Missing Values，在 Pandas 中常表示為 `NaN` - Not a Number) 是資料清理中最常見的問題之一。如果不及時處理，它們可能會導致分析錯誤或模型表現不佳。\n",
    "\n",
    "### 1. 檢查缺失值：`df.isnull().sum()`\n",
    "\n",
    "在處理缺失值之前，我們需要知道哪些欄位有多少缺失值。\n",
    "\n",
    "* `df.isnull()`：回傳一個與 DataFrame 形狀相同的布林值 DataFrame，`True` 表示該位置是缺失值，`False` 表示非缺失。\n",
    "* `.sum()`：對布林值 DataFrame 沿著欄位方向求和，`True` 會被視為 1，`False` 被視為 0，因此結果就是每個欄位的缺失值數量。\n",
    "\n",
    "### 2. 處理缺失值的方法\n",
    "\n",
    "最常見的兩種處理方法是：\n",
    "\n",
    "* **移除缺失值：`df.dropna()`**\n",
    "  * 預設會刪除**任何**含有缺失值的**行** (`axis=0`)。如果資料量夠大，且缺失值數量佔比較小，這是一個簡單的方法。\n",
    "  * **注意：** 這可能會刪除大量數據，要謹慎使用！\n",
    "* **填補缺失值：`df.fillna()`**\n",
    "  * 用特定的值（例如平均值、中位數、眾數、固定值）來填充缺失值。這是更常用的方法。\n",
    "  * 對於**數值型**資料(如 'Age')，常用**平均值** (`.mean()`) 或**中位數** (`.median()`) 填補。\n",
    "  * 對於**類別型**資料(如 'Embarked')，常用**眾數** (`.mode()`) 填補。\n",
    "  * **`inplace=True`：** 這個參數很重要！如果設置為 `True`，操作會直接修改原始 DataFrame；如果為 `False` (預設值)，則會回傳一個新的 DataFrame，原始 DataFrame 不變。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [新增] 為什麼要用 `.copy()`? 避免 `SettingWithCopyWarning`\n",
    "\n",
    "在後續操作中，你會經常看到我們先用 `df_new = df.copy()` 來複製一份資料再進行修改。\n",
    "\n",
    "**為什麼要這樣做？**\n",
    "\n",
    "在 Pandas 中，如果你直接對篩選出來的資料子集進行賦值，可能會觸發一個名為 `SettingWithCopyWarning` 的警告。這個警告提醒你，你的修改可能作用在一個暫時的「視圖 (View)」上，而不是你預期的原始 DataFrame 的副本，這可能導致修改沒有成功，或者產生不可預期的結果。\n",
    "\n",
    "為了避免這個困惑，最安全、最明確的做法是：**當你需要修改一個 DataFrame 的子集時，先用 `.copy()` 創造一個明確的副本，然後對這個副本進行操作。**\n",
    "\n",
    "```python\n",
    "# 好的作法\n",
    "df_processed = df.copy()\n",
    "# ... 在 df_processed 上進行各種修改 ...\n",
    "```\n",
    "\n",
    "這能確保你的修改操作作用在一個獨立的物件上，而不會影響到原始的 `df`，也避免了惱人的警告。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 檢查每個欄位的缺失值數量：df.isnull().sum()\n",
    "print(\"每個欄位的缺失值數量：\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\n從結果可以看出，'Age'、'Cabin' 和 'Embarked' 欄位有缺失值。\")\n",
    "print(\"'Cabin' 缺失的比例非常高，通常很難填補，後續可能會考慮直接刪除此欄位。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理缺失值方法一：移除含有缺失值的行 df.dropna()\n",
    "# 這裡我們只是示範，並不會真的修改我們的 df\n",
    "df_dropped = df.dropna()\n",
    "\n",
    "print(\"原資料形狀：\", df.shape)\n",
    "print(\"移除任何含有缺失值的行後，資料形狀：\", df_dropped.shape)\n",
    "print(f\"\\n觀察：我們只剩下 {df_dropped.shape[0]} 筆資料，損失了超過 80% 的數據！所以 dropna() 在此情境下不是個好方法。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 處理缺失值方法二：填補 'Age' 欄位的缺失值\n",
    "\n",
    "# 1. 計算 'Age' 欄位的平均值\n",
    "mean_age = df['Age'].mean()\n",
    "print(f\"Age 欄位的平均值：{mean_age:.2f}\")\n",
    "\n",
    "# 2. 使用平均值填充 'Age' 欄位的缺失值\n",
    "# 我們會先建立一個資料副本進行操作，以保持原始 df 的完整性 (好習慣！)\n",
    "df_filled_age = df.copy()\n",
    "df_filled_age['Age'].fillna(mean_age, inplace=True) # 使用 inplace=True 直接修改 df_filled_age\n",
    "\n",
    "print(\"\\n填充 Age 前，'Age' 欄位的缺失值數量：\", df['Age'].isnull().sum())\n",
    "print(\"填充 Age 後，'Age' 欄位的缺失值數量：\", df_filled_age['Age'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 6.2 練習題：處理 'Embarked' 缺失值\n",
    "\n",
    "現在，讓我們來練習處理另一個有缺失值的欄位：**'Embarked' (登船港口)**。\n",
    "\n",
    "觀察 `df.isnull().sum()` 的輸出，你會看到 'Embarked' 欄位也有少量缺失值。由於 'Embarked' 是一個類別型欄位，我們通常會使用**眾數 (most frequent value)** 來填充它。\n",
    "\n",
    "### 任務\n",
    "\n",
    "請運行以下程式碼，它試圖用眾數填充 'Embarked' 欄位，但程式碼有問題。請**觀察它的輸出 (雖然沒有報錯，但問題依然存在)，並嘗試修正**，使 'Embarked' 欄位的缺失值被正確填充。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 錯誤示範：請觀察輸出並修正！\n",
    "# 目標：用 'Embarked' 欄位的眾數填充缺失值\n",
    "\n",
    "# 1. 計算 'Embarked' 欄位的眾數\n",
    "most_frequent_embarked = df['Embarked'].mode() # .mode() 可能回傳一個 Series\n",
    "print(\"df['Embarked'].mode() 的回傳結果是：\")\n",
    "print(most_frequent_embarked)\n",
    "print(\"它的類型是：\", type(most_frequent_embarked))\n",
    "print(\"---觀察分隔線---\")\n",
    "\n",
    "# 2. 建立資料副本，並嘗試用眾數填充缺失值\n",
    "df_copy_embarked = df.copy()\n",
    "# 這個操作不會報錯，但因為 fillna 預期的是單一值，而你給了它一個 Series，它無法正確匹配並填充。\n",
    "df_copy_embarked['Embarked'].fillna(most_frequent_embarked, inplace=True)\n",
    "\n",
    "print(\"\\n填充 Embarked 後的缺失值情況：\")\n",
    "# 觀察：缺失值依然存在！表示填充失敗了。\n",
    "print(df_copy_embarked.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: 20px; color: blue; cursor: pointer;\">點我查看提示與解答 (請先嘗試自行修正後再展開)</summary>\n",
    "\n",
    "### 提示\n",
    "\n",
    "* `mode()` 函數會回傳一個 Series，而不是一個單一的值。這是因為資料中可能有多個眾數。即使只有一個眾數，它也會被包在一個 Series 裡。\n",
    "* `fillna()` 函數通常需要一個**單一的值** (純量) 來填充，而不是一個 Series。\n",
    "* 你需要從 `mode()` 返回的 Series 中，取出它的第一個（或唯一一個）值。你可以使用索引 `[0]` 來獲取 Series 中的第一個元素。\n",
    "\n",
    "### 正確程式碼\n",
    "\n",
    "```python\n",
    "# 正確的寫法\n",
    "# 這裡加上 [0] 來獲取 Series 中的第一個值 'S'\n",
    "most_frequent_embarked_correct = df['Embarked'].mode()[0] \n",
    "print(f\"正確的眾數值是: '{most_frequent_embarked_correct}' (類型: {type(most_frequent_embarked_correct)})\\n\")\n",
    "\n",
    "df_copy_embarked_correct = df.copy()\n",
    "df_copy_embarked_correct['Embarked'].fillna(most_frequent_embarked_correct, inplace=True)\n",
    "\n",
    "print(\"填充 Embarked 後的缺失值情況 (正確)：\")\n",
    "print(df_copy_embarked_correct.isnull().sum())\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 6.3 新增、修改、刪除欄位\n",
    "\n",
    "除了處理缺失值，我們也經常需要對資料欄位進行增、刪、改的操作，以適應分析或模型的需要。\n",
    "\n",
    "### 1. 新增欄位\n",
    "\n",
    "可以直接對 DataFrame 賦值來新增一個欄位，它的值可以是固定值、列表、或者基於現有欄位的計算結果。\n",
    "\n",
    "### 2. 修改欄位值\n",
    "\n",
    "直接對特定欄位進行賦值即可修改其值，也可以結合條件篩選來修改部分值。\n",
    "\n",
    "### 3. 刪除欄位/行：`df.drop()`\n",
    "\n",
    "使用 `df.drop()` 可以刪除指定的欄位或行。\n",
    "\n",
    "* **刪除欄位：** 傳入要刪除的欄位名稱 (可以是列表)，並設置 `axis=1` (表示操作的是**列**)。\n",
    "* **刪除行：** 傳入要刪除的行索引 (可以是列表)，並設置 `axis=0` (表示操作的是**行**)。\n",
    "* 同樣，這裡也可以使用 `inplace=True` 來直接修改原始 DataFrame。\n",
    "\n",
    "### 範例：新增一個『家庭人數』欄位 (特徵工程)\n",
    "\n",
    "鐵達尼號資料集中有 `SibSp` (兄弟姐妹/配偶數量) 和 `Parch` (父母/子女數量) 欄位。我們可以將它們相加並加 1 (加上乘客自己) 來創建一個新的欄位叫做 `FamilySize`，這可能對預測生存率很有用！這種從現有資料創造新特徵的過程，就稱為**特徵工程 (Feature Engineering)**。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我們先複製一份資料來進行操作，保持原始 df 的乾淨\n",
    "df_processed = df.copy()\n",
    "\n",
    "# 1. 新增 'FamilySize' 欄位\n",
    "df_processed['FamilySize'] = df_processed['SibSp'] + df_processed['Parch'] + 1\n",
    "\n",
    "print(\"新增 'FamilySize' 欄位後的前 5 行 (相關欄位)：\")\n",
    "print(df_processed[['SibSp', 'Parch', 'FamilySize']].head())\n",
    "\n",
    "# 2. 刪除欄位：我們認為 'Ticket' 和 'PassengerId' 對分析可能沒用，把它們刪除\n",
    "df_processed.drop(['Ticket', 'PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "print(\"\\n刪除欄位後，DataFrame 剩餘的欄位：\")\n",
    "print(df_processed.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 7.1 條件式篩選 (Boolean Indexing)\n",
    "\n",
    "資料篩選是資料分析中最常用的操作之一。它允許你根據特定的條件，從 DataFrame 中提取出符合條件的子集。\n",
    "\n",
    "在 Pandas 中，我們通常使用「**布林索引 (Boolean Indexing)**」來進行條件篩選。它的核心思想是：\n",
    "\n",
    "1.  創建一個布林 Series (由 `True` 和 `False` 組成)，表示 DataFrame 中每一行是否符合條件。\n",
    "2.  將這個布林 Series 放到 DataFrame 的中括號 `[]` 中，Pandas 就會自動篩選出所有對應 `True` 的行。\n",
    "\n",
    "### 邏輯運算符號\n",
    "\n",
    "當你需要結合多個條件時，請使用以下 Pandas/Python 的邏輯運算符號，**並且每個條件都必須用括號 `()` 包起來**：\n",
    "\n",
    "* **`&` (and)：** 兩個條件都必須為真。\n",
    "* **`|` (or)：** 兩個條件中至少一個為真。\n",
    "* **`~` (not)：** 將條件反轉 (真變假，假變真)。\n",
    "\n",
    "### 範例\n",
    "\n",
    "* **篩選所有女性乘客：** `df[df['Sex'] == 'female']`\n",
    "* **篩選頭等艙 (Pclass = 1) 的女性乘客：** `df[(df['Pclass'] == 1) & (df['Sex'] == 'female')]`\n",
    "\n",
    "讓我們實際操作看看！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選出所有女性乘客\n",
    "female_passengers = df[df['Sex'] == 'female']\n",
    "print(\"女性乘客數量：\", len(female_passengers))\n",
    "print(\"\\n女性乘客資料前 5 行：\")\n",
    "print(female_passengers.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 篩選出頭等艙 (Pclass = 1) 且存活 (Survived = 1) 的乘客\n",
    "# 注意每個條件都要用 () 包起來！\n",
    "first_class_survivors = df[(df['Pclass'] == 1) & (df['Survived'] == 1)]\n",
    "print(\"頭等艙存活乘客數量：\", len(first_class_survivors))\n",
    "print(\"\\n頭等艙存活乘客資料前 5 行：\")\n",
    "print(first_class_survivors.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 7.2 練習題：篩選高票價的年輕乘客\n",
    "\n",
    "現在，請你來試試看多條件篩選！\n",
    "\n",
    "請運行以下程式碼，它試圖篩選出 **票價 (Fare) 大於 50 且年齡 (Age) 小於 18 歲** 的乘客。但程式碼有問題。請**觀察錯誤訊息，並嘗試修正**。\n",
    "\n",
    "### 任務\n",
    "\n",
    "1.  運行下方的 Code Cell。\n",
    "2.  仔細閱讀錯誤訊息，它會告訴你哪裡不對勁。\n",
    "3.  根據錯誤訊息和提示，修正程式碼，使其能成功篩選出符合條件的乘客。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 錯誤示範：請觀察錯誤訊息並修正！\n",
    "# 目標：篩選票價大於 50 且年齡小於 18 歲的乘客\n",
    "young_rich_passengers = df[df['Fare'] > 50 and df['Age'] < 18]\n",
    "print(young_rich_passengers.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: 20px; color: blue; cursor: pointer;\">點我查看提示與解答 (請先嘗試自行修正後再展開)</summary>\n",
    "\n",
    "### 提示\n",
    "\n",
    "* 錯誤訊息 `ValueError: The truth value of a Series is ambiguous...` 是一個經典錯誤。它表示你正在嘗試對整個 Series (例如 `df['Fare'] > 50` 的結果) 使用 Python 原生的 `and` 關鍵字，但 `and` 不知道該如何處理一個包含多個 `True`/`False` 值的 Series。\n",
    "* 在 Pandas 中進行多條件篩選時，不能直接使用 Python 的 `and` 或 `or` 關鍵字。你需要使用 Pandas 的位元運算符：**`&` (用於邏輯 AND)** 和 **`|` (用於邏輯 OR)**。\n",
    "* **非常重要：每個獨立的條件都需要用括號 `()` 包起來**，這是為了確保運算的優先級正確。\n",
    "\n",
    "### 正確程式碼\n",
    "\n",
    "```python\n",
    "# 正確的寫法\n",
    "young_rich_passengers_correct = df[(df['Fare'] > 50) & (df['Age'] < 18)]\n",
    "print(young_rich_passengers_correct.head())\n",
    "print(\"\\n符合條件的乘客數量：\", len(young_rich_passengers_correct))\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 7.3 排序資料：`df.sort_values()`\n",
    "\n",
    "排序是整理資料的另一個基本操作，它能讓你按照特定欄位的值，將 DataFrame 的行重新排列。\n",
    "\n",
    "使用 `df.sort_values()` 方法，你可以：\n",
    "\n",
    "* **`by='ColumnName'`：** 指定要根據哪個欄位來排序。也可以傳入一個列表 `by=['Col1', 'Col2']` 進行多重排序。\n",
    "* **`ascending=True` (預設值)：** 升序排序 (從小到大)。\n",
    "* **`ascending=False`：** 降序排序 (從大到小)。\n",
    "\n",
    "### 範例\n",
    "\n",
    "讓我們來按照乘客的票價 (`Fare`) 進行降序排序，看看誰付的錢最多。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根據 'Fare' 欄位降序排序，找出票價最高的乘客\n",
    "df_sorted_fare = df.sort_values(by='Fare', ascending=False)\n",
    "print(\"按票價降序排序的前 10 行：\")\n",
    "print(df_sorted_fare.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 8.1 分組聚合 (GroupBy) 的概念：Split-Apply-Combine\n",
    "\n",
    "**`GroupBy`** 是 Pandas 中**最為強大和靈活**的資料分析工具之一。它允許你根據一個或多個欄位的值，將資料分成不同的組，然後對每個組獨立地執行操作。\n",
    "\n",
    "GroupBy 操作可以被形象地理解為「**Split-Apply-Combine**」三個步驟：\n",
    "\n",
    "1.  **Split (分割)：** 根據你指定的鍵 (一個或多個欄位)，將 DataFrame 分割成多個較小的組 (Group)。例如，你可以按 `Sex` (性別) 將乘客分成「男性組」和「女性組」。\n",
    "2.  **Apply (應用)：** 對每個獨立的組，應用一個函數。這可以是聚合函數 (如 `mean()` 平均值、`sum()` 總和、`count()` 計數)、轉換函數、或過濾函數。例如，你可以計算每個性別組的「平均生存率」。\n",
    "3.  **Combine (組合)：** 將每個組的處理結果組合起來，形成一個新的 Series 或 DataFrame，作為最終的輸出。\n",
    "\n",
    "下圖清晰展示了 Split-Apply-Combine 的流程：\n",
    "\n",
    "![Split-Apply-Combine](https://pandas.pydata.org/docs/getting_started/overview/_images/03_groupby_two_variables.svg)\n",
    "圖片來源: Pandas 官方文件\n",
    "\n",
    "### 範例：計算不同性別的平均生存率\n",
    "\n",
    "在鐵達尼號資料中，`Survived` 欄位是 1 (生存) 或 0 (死亡)。因此，一個組的 `Survived` 平均值就代表了該組的**生存率**。\n",
    "\n",
    "讓我們來看看不同性別的生存率是多少？以及不同艙等的平均票價？\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：計算不同性別的平均生存率\n",
    "# 步驟：\n",
    "# 1. df.groupby('Sex')：將資料按 'Sex' 欄位分成 'female' 和 'male' 兩組\n",
    "# 2. ['Survived']：從分組後的物件中，選取 'Survived' 欄位\n",
    "# 3. .mean()：對每一組的 'Survived' 值計算平均值\n",
    "survival_rate_by_sex = df.groupby('Sex')['Survived'].mean()\n",
    "\n",
    "print(\"不同性別的生存率：\")\n",
    "print(survival_rate_by_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 範例：計算不同艙等 (Pclass) 的平均票價\n",
    "avg_fare_by_pclass = df.groupby('Pclass')['Fare'].mean()\n",
    "\n",
    "print(\"\\n不同艙等的平均票價：\")\n",
    "print(avg_fare_by_pclass)\n",
    "print(\"\\n觀察：艙等等級越高(數字越小)，平均票價也越高，符合預期。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 8.2 練習題：計算不同艙等和性別的平均生存率\n",
    "\n",
    "現在，你已經理解了 `groupby` 的基本概念。讓我們來挑戰一個稍微複雜一點的練習：**同時根據『艙等 (Pclass)』和『性別 (Sex)』來計算平均生存率**。\n",
    "\n",
    "請運行以下程式碼，它試圖完成這個任務，但程式碼有問題。請**觀察錯誤訊息，並嘗試修正**。\n",
    "\n",
    "### 任務\n",
    "\n",
    "1.  運行下方的 Code Cell。\n",
    "2.  仔細閱讀錯誤訊息。\n",
    "3.  根據錯誤訊息和提示，修正程式碼，使其能成功計算出不同艙等和性別組合下的平均生存率。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 錯誤示範：請觀察錯誤訊息並修正！\n",
    "# 目標：計算不同艙等和性別的平均生存率\n",
    "survival_rate_complex = df.groupby('Pclass', 'Sex')['Survived'].mean()\n",
    "print(survival_rate_complex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary style=\"font-size: 20px; color: blue; cursor: pointer;\">點我查看提示與解答 (請先嘗試自行修正後再展開)</summary>\n",
    "\n",
    "### 提示\n",
    "\n",
    "* 錯誤訊息 `TypeError: groupby() got multiple values for argument 'by'` 表明你給 `groupby()` 傳遞了多個單獨的參數 ('Pclass' 和 'Sex')，但它只期望一個 `by` 參數。\n",
    "* 當你想要使用**多個欄位**進行 `groupby` 時，你需要將這些欄位名稱放在一個**列表 (List)** 中，然後將這個列表傳遞給 `by` 參數。\n",
    "\n",
    "### 正確程式碼\n",
    "\n",
    "```python\n",
    "# 正確的寫法：將多個分組欄位放入一個列表中\n",
    "survival_rate_complex_correct = df.groupby(['Pclass', 'Sex'])['Survived'].mean()\n",
    "print(survival_rate_complex_correct)\n",
    "\n",
    "# 觀察結果：你可以看到一個有兩層索引 (Pclass, Sex) 的 Series，\n",
    "# 這清楚地顯示了在每個艙等中，女性的存活率都遠高於男性。\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 9.1 簡單資料視覺化 (Data Visualization)\n",
    "\n",
    "「一圖勝千言。」資料視覺化是資料分析中非常重要的一環，它能幫助我們直觀地理解資料中的模式、趨勢和異常。\n",
    "\n",
    "Pandas 的 `DataFrame` 和 `Series` 物件都內建了 `plot()` 方法，這使得快速生成基本圖表變得非常方便。這個 `plot()` 方法底層是基於強大的 **Matplotlib** 函式庫。\n",
    "\n",
    "### 範例：繪製不同性別生存率的長條圖\n",
    "\n",
    "我們將使用之前計算出的 `survival_rate_by_sex` (不同性別生存率) 來繪製一個長條圖。\n",
    "\n",
    "* **`kind='bar'`：** 指定要繪製的圖表類型為**長條圖**。其他常用類型還有 `'line'` (折線圖), `'hist'` (直方圖), `'scatter'` (散點圖)等。\n",
    "* `plt.ylabel()`, `plt.title()`：可以用來添加 Y 軸標籤和圖表標題，讓圖表更清晰。\n",
    "* `plt.xticks(rotation=0)`：將 X 軸的標籤旋轉 0 度 (即水平顯示)，防止文字重疊。\n",
    "* `plt.tight_layout()`：自動調整圖表邊距，確保標題、標籤等元素不會被裁切掉。\n",
    "* `plt.show()`：顯示圖表。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 為了顯示圖表，我們需要導入 matplotlib.pyplot 函式庫，並簡稱為 plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 確保 survival_rate_by_sex 已經被計算出來，以防學員跳過前面的步驟\n",
    "survival_rate_by_sex = df.groupby('Sex')['Survived'].mean()\n",
    "\n",
    "# 繪製不同性別生存率的長條圖\n",
    "survival_rate_by_sex.plot(kind='bar')\n",
    "\n",
    "# 添加標籤和標題，讓圖表更易懂\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.xlabel('Sex')\n",
    "plt.xticks(rotation=0) # 將 x 軸標籤（'female', 'male'）水平顯示\n",
    "plt.tight_layout()   # 自動調整佈局，避免標籤被裁切\n",
    "\n",
    "plt.show() # 顯示圖表\n",
    "\n",
    "# 從圖中可以一目了然地看到，女性的存活率遠高於男性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 10.1 開放式練習：用你的想法清理與準備資料！\n",
    "\n",
    "恭喜你，已經學會了 Pandas 的基礎操作！現在，是時候將這些技能應用到一個更**開放**和**實際**的任務中。\n",
    "\n",
    "在前面的步驟中，我們已經對鐵達尼號資料進行了初步探索和一些簡單的清理。現在，我們想請你運用所學，對 `df` 這個 DataFrame 進行進一步的**資料清理和預處理**。\n",
    "\n",
    "### 你的任務目標\n",
    "\n",
    "嘗試將資料清理成一個 **更適合進行機器學習模型訓練** 的狀態。機器學習模型通常只能理解數值，所以我們的目標是：\n",
    "1.  **處理所有缺失值**。\n",
    "2.  **將所有非數值欄位轉換為數值**。\n",
    "3.  **移除不需要的欄位**。\n",
    "4.  **創造可能有用的新特徵 (特徵工程)**。\n",
    "\n",
    "### 建議步驟\n",
    "\n",
    "* **處理缺失值：**\n",
    "  * `Age`: 用平均值或中位數填充。\n",
    "  * `Embarked`: 用眾數填充。\n",
    "  * `Cabin`: 缺失值太多，可以直接**刪除**此欄位。\n",
    "* **處理不需要的欄位：** `Name`, `Ticket`, `PassengerId` 等欄位對預測生存率沒有直接幫助，可以考慮刪除它們。\n",
    "* **將類別型資料轉換為數值型資料：**\n",
    "  * `Sex` 欄位 ('female', 'male') 可以轉換為 `1` 和 `0`。\n",
    "  * `Embarked` 欄位 ('S', 'C', 'Q')，因為有多個類別，需要使用 **獨熱編碼 (One-Hot Encoding)** 來處理。Pandas 的 `pd.get_dummies()` 函數非常適合這個任務。\n",
    "* **創建新的特徵 (Feature Engineering)：** 你可以像我們之前新增 `FamilySize` 欄位那樣，從現有數據中組合出新的有意義的欄位。\n",
    "\n",
    "### 自由發揮！\n",
    "\n",
    "請盡量發揮你的創意，沒有標準答案！我們鼓勵你嘗試不同的方法。在你完成清理後，請命名你的最終 DataFrame 為 `df_cleaned_for_dl`。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在此進行你的資料清理與預處理！\n",
    "\n",
    "# 強烈建議：首先複製原始資料，避免修改到原始的 df\n",
    "df_cleaned_for_dl = df.copy()\n",
    "\n",
    "# --- 以下是你可以開始寫程式碼的地方 (你可以根據你的想法刪除或修改這些範例程式碼) --- \n",
    "\n",
    "print(\"清理前的缺失值：\\n\", df_cleaned_for_dl.isnull().sum())\n",
    "print(\"\\n--- 開始清理 ---\\n\")\n",
    "\n",
    "# 1. 處理缺失值\n",
    "# 處理 'Age' 缺失值：用平均值填充\n",
    "df_cleaned_for_dl['Age'].fillna(df_cleaned_for_dl['Age'].mean(), inplace=True)\n",
    "\n",
    "# 處理 'Embarked' 缺失值：用眾數填充\n",
    "df_cleaned_for_dl['Embarked'].fillna(df_cleaned_for_dl['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# 2. 刪除你認為不需要的欄位\n",
    "# 'Cabin' 缺失值太多，'Name', 'Ticket', 'PassengerId' 對模型來說是雜訊\n",
    "df_cleaned_for_dl.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)\n",
    "\n",
    "# 3. 將類別型資料轉換為數值\n",
    "# 將 'Sex' 欄位轉換為數值 (0 或 1)\n",
    "# .map() 是一個方便的轉換工具\n",
    "df_cleaned_for_dl['Sex'] = df_cleaned_for_dl['Sex'].map({'female': 1, 'male': 0})\n",
    "\n",
    "# 對 'Embarked' 進行獨熱編碼 (One-Hot Encoding)\n",
    "# drop_first=True 可以避免「共線性」問題，這是機器學習中的一個好習慣\n",
    "df_cleaned_for_dl = pd.get_dummies(df_cleaned_for_dl, columns=['Embarked'], drop_first=True)\n",
    "\n",
    "# 4. 新增 'FamilySize' 欄位 (特徵工程)\n",
    "df_cleaned_for_dl['FamilySize'] = df_cleaned_for_dl['SibSp'] + df_cleaned_for_dl['Parch'] + 1\n",
    "\n",
    "# --- 你的清理工作到此結束，請確保最終 DataFrame 名稱為 df_cleaned_for_dl ---\n",
    "\n",
    "print(\"\\n--- 清理完成 ---\\n\")\n",
    "print(\"你的清理成果：\")\n",
    "print(\"清理後的資料形狀：\", df_cleaned_for_dl.shape)\n",
    "print(\"\\n清理後的缺失值：\\n\", df_cleaned_for_dl.isnull().sum()) # 應該都沒有缺失值了\n",
    "print(\"\\n清理後資料的前 5 行：\")\n",
    "print(df_cleaned_for_dl.head())\n",
    "print(\"\\n清理後資料的所有欄位：\", df_cleaned_for_dl.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 11.1 深度學習小模型：看看你的資料影響力！\n",
    "\n",
    "現在，讓我們看看你清理好的資料如何影響一個簡單的**深度學習模型**！\n",
    "\n",
    "我們將使用 **PyTorch**，一個強大的開源機器學習框架，來建立一個非常簡單的神經網路，預測乘客的生存率。你**不需要理解這個模型的每一個細節**，這個環節的重點是觀察：\n",
    "\n",
    "* **資料處理是機器學習流程中不可或缺的一環。**\n",
    "* **好的資料品質對模型表現至關重要 (Garbage In, Garbage Out)。**\n",
    "* 這是你為未來深度學習工作坊建立連結的**第一個真實體驗**！\n",
    "\n",
    "請運行以下的 Cells，看看你的資料清理成果能讓模型達到多少的預測準確度 (Accuracy)！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入 PyTorch 和其他必要的函式庫\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"PyTorch 和相關函式庫載入成功！\")\n",
    "\n",
    "# --- 資料準備：將 DataFrame 轉換為模型可用的格式 ---\n",
    "\n",
    "# 再次檢查你的 df_cleaned_for_dl，確保它是存在的\n",
    "try:\n",
    "    df_cleaned_for_dl\n",
    "except NameError:\n",
    "    print(\"錯誤：找不到 df_cleaned_for_dl，請確認你已經運行了上面的開放式練習 Cell！\")\n",
    "    # 如果學員沒有運行，這裡可以選擇停止或提供一個預設的清理版本\n",
    "    # 為了工作坊順利，我們假設它存在\n",
    "\n",
    "# 選擇用於模型訓練的特徵 (輸入變數 X) 和目標變數 (預測目標 y)\n",
    "# 目標是 'Survived'，其他所有欄位都是特徵\n",
    "X = df_cleaned_for_dl.drop('Survived', axis=1)\n",
    "y = df_cleaned_for_dl['Survived']\n",
    "\n",
    "# 資料標準化 (Standardization)：\n",
    "# 這是深度學習中非常重要的一步。因為不同特徵的數值範圍差異很大 (如 Age 和 Fare)，\n",
    "# 標準化可以將所有特徵縮放到相似的範圍，有助於模型更快、更穩定地學習。\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 分割訓練集和測試集：\n",
    "# 我們將資料分為「訓練集」(用來訓練模型)和「測試集」(用來評估模型表現)。\n",
    "# test_size=0.2 表示 20% 的資料用於測試。\n",
    "# random_state=42 確保每次分割結果都一樣，方便重現實驗。\n",
    "# [修改] 這裡我們傳入 y (Pandas Series)，而不是 y.values，這樣 y_test 就會保留原始的索引，方便後續分析\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 轉換為 PyTorch 張量 (Tensor)：PyTorch 模型需要輸入張量格式的數據\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).unsqueeze(1) # unsqueeze(1) 將一維張量變為二維列向量\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "print(\"\\n資料準備完成！\")\n",
    "print(f\"用於訓練的特徵欄位 ({X.shape[1]}個): {X.columns.tolist()}\")\n",
    "print(\"訓練集特徵形狀：\", X_train_tensor.shape)\n",
    "print(\"測試集特徵形らなかった：\", X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [修改] 建立並訓練一個簡單的 PyTorch 神經網路 (增加 Loss 記錄)\n",
    "\n",
    "# 1. 定義神經網路模型\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.output_layer = nn.Linear(32, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "# 2. 實例化模型、定義損失函數和優化器\n",
    "input_size = X_train_tensor.shape[1]\n",
    "model = SimpleNN(input_size)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 3. 訓練模型\n",
    "num_epochs = 100\n",
    "losses = [] # [新增] 用來記錄每一輪的 loss\n",
    "print(f\"\\n開始訓練深度學習模型，共 {num_epochs} 個 Epoch (訓練輪數)...\" )\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item()) # [新增] 記錄 loss\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print(\"\\n模型訓練完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估模型表現：預測生存率\n",
    "\n",
    "print(\"\\n開始評估模型在『測試集』上的表現...\")\n",
    "\n",
    "# 設置模型為評估模式\n",
    "model.eval()\n",
    "\n",
    "# 在測試集上進行預測\n",
    "with torch.no_grad(): \n",
    "    test_outputs = model(X_test_tensor)\n",
    "    predicted = (test_outputs >= 0.5).float()\n",
    "    accuracy = accuracy_score(y_test_tensor.numpy(), predicted.numpy())\n",
    "\n",
    "print(f\"\\n模型在測試集上的準確度 (Accuracy): {accuracy:.4f} ({accuracy*100:.2f} %)\")\n",
    "\n",
    "print(\"\\n---\")\n",
    "print(\"思考：你的資料清理方法是否讓這個準確度更高或更低？\")\n",
    "print(\"嘗試回到 \\\"10.1 開放式練習\\\" 區塊，修改你的清理方式，然後重新運行所有深度學習的 Cells，觀察準確度的變化！\")\n",
    "print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 12. 深入分析模型表現\n",
    "\n",
    "只看一個準確率數字是不夠的！一個好的資料科學家，會像偵探一樣，深入挖掘模型為什麼會做對、又為什麼會犯錯。讓我們開始吧！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 視覺化學習過程：模型是如何進步的？\n",
    "\n",
    "我們可以把剛剛訓練過程中，每一輪的「損失 (Loss)」畫出來，觀察模型的學習曲線。\n",
    "\n",
    "可以把它想像成一個學生（模型）在念書（訓練）的過程。X 軸是念書的時間（訓練輪次），Y 軸是考試的「錯誤扣分」（損失值）。\n",
    "\n",
    "一個理想的學生，應該會越念錯得越少，所以我們**期望看到一條平滑向下的曲線**，這代表模型確實學到了東西，並且越來越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 繪製 Loss 曲線\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 分析模型的錯誤：它在哪些人身上看走了眼？\n",
    "\n",
    "模型不是萬能的，它總會犯錯。我們的目標是找出被模型「誤判」的乘客，看看他們有沒有什麼共同特徵。這能幫助我們理解模型的弱點，甚至啟發我們回到前面的步驟，做更好的「特徵工程」。\n",
    "\n",
    "我們會看兩種主要的錯誤：\n",
    "* **偽陰性 (False Negative)**：乘客明明**存活**了，模型卻預測他**死亡**。(模型過於悲觀)\n",
    "* **偽陽性 (False Positive)**：乘客明明**死亡**了，模型卻預測他**存活**。(模型過於樂觀)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步驟 1: 找出所有錯誤案例\n",
    "\n",
    "# 將 PyTorch Tensor 轉回 Numpy array，方便比較\n",
    "y_test_numpy = y_test.values\n",
    "predicted_numpy = predicted.numpy().flatten() # .flatten() 將 [[0],[1],...] 轉為 [0,1,...]\n",
    "\n",
    "# 找出預測與實際不符的樣本\n",
    "error_mask = (y_test_numpy != predicted_numpy)\n",
    "error_indices = y_test[error_mask].index\n",
    "\n",
    "# 從原始的 df 中，利用索引找出這些錯誤案例的完整資料\n",
    "df_errors = df.loc[error_indices].copy() # .copy() 是個好習慣\n",
    "\n",
    "# 新增欄位，方便我們對照「真實」與「預測」結果\n",
    "df_errors['Actual_Survived'] = y_test[error_mask]\n",
    "df_errors['Predicted_Survived'] = predicted_numpy[error_mask].astype(int)\n",
    "\n",
    "print(f\"在 {len(y_test)} 個測試樣本中，模型總共預測錯誤了 {len(df_errors)} 個。\")\n",
    "print(\"\\n以下是部分錯誤案例：\")\n",
    "df_errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.3 錯誤案例分佈 vs. 整體分佈\n",
    "\n",
    "現在我們有了所有錯誤案例的清單 `df_errors`。一個有趣的問題是：\n",
    "\n",
    "> **被模型誤判的這群人，他們的分佈，和全部的測試乘客分佈，有什麼不一樣嗎？**\n",
    "\n",
    "如果我們發現，錯誤案例中「三等艙」的比例特別高，這可能就代表模型對於判斷三等艙乘客的生死比較沒把握。讓我們來比較看看 `Pclass` (艙等) 和 `Sex` (性別) 的分佈。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步驟 2: 比較錯誤案例與整體測試集的分佈\n",
    "\n",
    "# 先取得整個測試集的原始資料，方便對比\n",
    "df_test_set = df.loc[y_test.index]\n",
    "\n",
    "print(\"--- Pclass (艙等) 分佈比較 ---\")\n",
    "print(\"\\n整體測試集 Pclass 分佈:\")\n",
    "print(df_test_set['Pclass'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\n錯誤案例 Pclass 分佈:\")\n",
    "print(df_errors['Pclass'].value_counts(normalize=True).sort_index())\n",
    "\n",
    "print(\"\\n--- Sex (性別) 分佈比較 ---\")\n",
    "print(\"\\n整體測試集 Sex 分佈:\")\n",
    "print(df_test_set['Sex'].value_counts(normalize=True).sort_index())\n",
    "print(\"\\n錯誤案例 Sex 分佈:\")\n",
    "print(df_errors['Sex'].value_counts(normalize=True).sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.4 個案分析：看看幾個具體的例子\n",
    "\n",
    "數字統計還不夠，讓我們來看看幾個「活生生」的例子，更能感受到模型判斷的盲點。\n",
    "\n",
    "**思考：**\n",
    "看看下面的例子，試著猜想一下，模型為什麼會判斷錯誤？是不是因為我們的特徵還不夠豐富？\n",
    "例如，`Name` 欄位裡其實包含了稱謂 (Mr., Mrs., Miss., Master.)，這可能也暗示了年齡或社會地位，但我們在清理時把它刪掉了。這會不會是原因之一呢？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步驟 3: 查看具體錯誤個案\n",
    "\n",
    "# 篩選出「偽陰性」案例 (實際存活，但被預測為死亡)\n",
    "false_negatives = df_errors[df_errors['Actual_Survived'] == 1]\n",
    "print(\"--- 錯誤案例：偽陰性 (實際存活，但被預測為死亡) ---\")\n",
    "display(false_negatives.head())\n",
    "\n",
    "# 篩選出「偽陽性」案例 (實際死亡，但被預測為存活)\n",
    "false_positives = df_errors[df_errors['Actual_Survived'] == 0]\n",
    "print(\"\\n--- 錯誤案例：偽陽性 (實際死亡，但被預測為存活) ---\")\n",
    "display(false_positives.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 13.1 工作坊總結\n",
    "\n",
    "恭喜你，完成了這個 Python + Pandas 新手工作坊！\n",
    "\n",
    "你已經學習並實踐了：\n",
    "\n",
    "* **Pandas 的核心概念：** Series 和 DataFrame。\n",
    "* **資料載入與初步探索：** 了解數據的第一步。\n",
    "* **關鍵的資料清理技術：** 處理缺失值、增刪改欄位。\n",
    "* **資料篩選與排序：** 根據需求提取和整理數據。\n",
    "* **強大的分組聚合：** 從數據中提煉洞見。\n",
    "* **基礎資料視覺化：** 讓數據說話。\n",
    "* **最重要的是，你親身體驗了從資料清理到模型訓練，再到模型分析的完整流程！** \n",
    "\n",
    "你學到了模型的評估**不只是一個準確率數字**。我們還要學會分析它的學習過程、解讀它的錯誤，並回頭思考如何透過更好的資料清理或特徵工程，來打造一個更聰明的模型。這就是資料科學家工作的核心循環：**Data -> Model -> Analysis -> back to Data**。\n",
    "\n",
    "你已經為自己未來的資料科學與深度學習之路打下了堅實的基礎。數據處理是一切的開始，掌握了它，你就掌握了數據的力量！\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "## 13.2 額外學習資源與未來展望\n",
    "\n",
    "學習資料科學是一個持續的過程，這個工作坊只是個開始！\n",
    "\n",
    "### 繼續探索 Pandas 與資料分析\n",
    "\n",
    "* **更多 Pandas 練習題：** 網路上有許多免費的 Pandas 練習題專案，例如：\n",
    "  * [Joyful Pandas (中文)](https://github.com/datawhalechina/joyful-pandas)\n",
    "  * [Kaggle 上的各種資料集和 Notebook](https://www.kaggle.com/datasets) - 找一個你感興趣的資料集開始探索！\n",
    "* **Pandas 官方文件：** 這是最權威的學習資源，雖然有些進階，但遇到問題時是最好的查詢手冊。\n",
    "  * [https://pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)\n",
    "\n",
    "### 邁向深度學習\n",
    "\n",
    "* **PyTorch/TensorFlow 入門：** 如果你對深度學習感興趣，可以開始學習 PyTorch 或 TensorFlow 的入門教程。它們是當前最主流的深度學習框架。\n",
    "  * [PyTorch 官方教程](https://pytorch.org/tutorials/)\n",
    "  * [TensorFlow 官方教程](https://www.tensorflow.org/tutorials)\n",
    "* **機器學習/深度學習相關課程：** 許多線上平台 (如 Coursera, Udacity, edX) 都提供優秀的機器學習和深度學習課程。\n",
    "\n",
    "### 保持實踐！\n",
    "\n",
    "最重要的就是**不斷地實踐**！找一個你感興趣的資料集，嘗試用 Pandas 去探索、清理和分析它。你會在動手做的過程中學到最多。\n",
    "\n",
    "期待在未來的深度學習工作坊中再次與你相見！\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
